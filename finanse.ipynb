import pandas as pd
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score
from imblearn.over_sampling import SMOTE
from collections import Counter
from imblearn.under_sampling import RandomUnderSampler
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import cross_val_score
#from sklearn.pipeline import Pipeline
from imblearn.pipeline import make_pipeline
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import cross_val_score
from statistics import mean
from sklearn.metrics import classification_report

file_path = '/content/creditcard.csv'
df = pd.read_csv(file_path)

print(df)

target_count = df['Class'].value_counts()
target_count

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report
X = df.drop(columns=['Class'])  # Features
y = df['Class']  # Labels
# Podziel dane na zbiór treningowy i testowy
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicjalizuj klasyfikator k-NN
knn_classifier = KNeighborsClassifier(n_neighbors=3)  # Możesz dostosować wartość k (liczbę sąsiadów)

# Trenuj klasyfikator na zbiorze treningowym
knn_classifier.fit(X_train, y_train)

# Przewiduj etykiety dla zbioru testowego
y_pred = knn_classifier.predict(X_test)

# Ocen dokładność klasyfikatora
accuracy = accuracy_score(y_test, y_pred)
print(f'Dokładność klasyfikatora: {accuracy:.2f}')

# Wyświetl raport klasyfikacji
classification_rep = classification_report(y_test, y_pred)
print('Raport klasyfikacji:\n', classification_rep)
